{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under the Hood of Encrypted Neural Networks\n",
    "\n",
    "This tutorial is optional, and can be skipped without loss of continuity.\n",
    "\n",
    "In this tutorial, we'll take a look at how CrypTen performs inference with an encrypted neural network on encrypted data. We'll see how the data remains encrypted through all the operations, and yet is able to obtain accurate results after the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "\n",
    "crypten.init() \n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings; \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Keep track of all created temporary files so that we can clean up at the end\n",
    "temp_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Linear Layer\n",
    "We'll start by examining how a single Linear layer works in CrypTen. We'll instantiate a torch Linear layer, convert to CrypTen layer, encrypt it, and step through some toy data with it. As in earlier tutorials, we'll assume Alice has the rank 0 process and Bob has the rank 1 process. We'll also assume Alice has the layer and Bob has the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ALICE and BOB src values\n",
    "ALICE = 0\n",
    "BOB = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintext Weights:\n",
      "\n",
      " Parameter containing:\n",
      "tensor([[-0.3788, -0.3863,  0.2494, -0.3814],\n",
      "        [ 0.1891,  0.0945, -0.0866,  0.0338]], requires_grad=True)\n",
      "\n",
      "Plaintext Bias:\n",
      "\n",
      " Parameter containing:\n",
      "tensor([-0.2243, -0.0173], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate single Linear layer\n",
    "layer_linear = nn.Linear(4, 2)\n",
    "\n",
    "# The weights and the bias are initialized to small random values\n",
    "print(\"Plaintext Weights:\\n\\n\", layer_linear._parameters['weight'])\n",
    "print(\"\\nPlaintext Bias:\\n\\n\", layer_linear._parameters['bias'])\n",
    "\n",
    "# Save the plaintext layer\n",
    "layer_linear_file = \"/tmp/tutorial5_layer_alice1.pth\"\n",
    "crypten.save(layer_linear, layer_linear_file)\n",
    "temp_files.append(layer_linear_file) \n",
    "\n",
    "# Generate some toy data\n",
    "features = 4\n",
    "examples = 3\n",
    "toy_data = torch.rand(examples, features)\n",
    "\n",
    "# Save the plaintext toy data\n",
    "toy_data_file = \"/tmp/tutorial5_data_bob1.pth\"\n",
    "crypten.save(toy_data, toy_data_file)\n",
    "temp_files.append(toy_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " tensor([[-1286493042698271882, -9140403225553337217,  5020745553221493222,\n",
      "           510324583582460464],\n",
      "        [-1997385621326979012,  2497757992816584923,  -592031035168176969,\n",
      "           855732634611796988]])\n",
      "Bias:\n",
      " tensor([-7587817823389855568, -7843596220216760560]) \n",
      "\n",
      "Get attribute forward\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([[ 9056021858841249393,  1357341164648941615, -1958202917556121332,\n",
      "         -2801381751205416112],\n",
      "        [ 6040481062770023678, -5636633128019382240,  -544177159464462195,\n",
      "         -2062296708234777555],\n",
      "        [-1534582366790462654,  7230538178060863873, -6485669428604171022,\n",
      "         -2892708247144764381]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([[-1286493042698271882, -1997385621326979012],\n",
      "        [-9140403225553337217,  2497757992816584923],\n",
      "        [ 5020745553221493222,  -592031035168176969],\n",
      "        [  510324583582460464,   855732634611796988]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n",
      "Get attribute forward\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([[-9056021858841212632, -1357341164648881929,  1958202917556164742,\n",
      "          2801381751205441167],\n",
      "        [-6040481062770004605,  5636633128019411653,   544177159464521079,\n",
      "          2062296708234785208],\n",
      "        [ 1534582366790494480, -7230538178060801350,  6485669428604204879,\n",
      "          2892708247144810753]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([[ 1286493042698247057,  1997385621326991406],\n",
      "        [ 9140403225553311900, -2497757992816578730],\n",
      "        [-5020745553221476880,   592031035168171296],\n",
      "        [ -510324583582485461,  -855732634611794775]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"<ipython-input-4-12b4156f1ef3>\", line 19, in forward_single_encrypted_layer\n",
      "    result_enc = layer_enc.forward(data_enc)\n",
      "  File \"<ipython-input-4-12b4156f1ef3>\", line 19, in forward_single_encrypted_layer\n",
      "    result_enc = layer_enc.forward(data_enc)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 538, in forward_function\n",
      "    res = object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 538, in forward_function\n",
      "    res = object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 1465, in forward\n",
      "    output = x.matmul(self.weight.t())\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 1465, in forward\n",
      "    output = x.matmul(self.weight.t())\n",
      "  File \"/home/george/contrib/CrypTen/crypten/cryptensor.py\", line 299, in autograd_forward\n",
      "    result = grad_fn.forward(ctx, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/cryptensor.py\", line 299, in autograd_forward\n",
      "    result = grad_fn.forward(ctx, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/gradients.py\", line 697, in forward\n",
      "    return input.matmul(other)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/gradients.py\", line 697, in forward\n",
      "    return input.matmul(other)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/mpc.py\", line 54, in convert_wrapper\n",
      "    return func(result, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/mpc.py\", line 54, in convert_wrapper\n",
      "    return func(result, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/mpc.py\", line 1263, in ob_wrapper_function\n",
      "    result._tensor = getattr(result._tensor, name)(value, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/mpc.py\", line 1263, in ob_wrapper_function\n",
      "    result._tensor = getattr(result._tensor, name)(value, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 438, in matmul\n",
      "    return self._arithmetic_function(y, \"matmul\")\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 438, in matmul\n",
      "    return self._arithmetic_function(y, \"matmul\")\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 345, in _arithmetic_function\n",
      "    return result.div_(result.encoder.scale)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 345, in _arithmetic_function\n",
      "    return result.div_(result.encoder.scale)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 415, in div_\n",
      "    self.share = self.share.div_(y, rounding_mode=\"trunc\")\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/primitives/arithmetic.py\", line 415, in div_\n",
      "    self.share = self.share.div_(y, rounding_mode=\"trunc\")\n",
      "TypeError: div_() got an unexpected keyword argument 'rounding_mode'\n",
      "TypeError: div_() got an unexpected keyword argument 'rounding_mode'\n",
      "ERROR:root:One of the parties failed. Check past logs\n"
     ]
    }
   ],
   "source": [
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def forward_single_encrypted_layer():\n",
    "    # Load and encrypt the layer\n",
    "    layer = crypten.load_from_party(layer_linear_file, src=ALICE)\n",
    "    layer_enc = crypten.nn.from_pytorch(layer, dummy_input=torch.empty((1,4)))\n",
    "    layer_enc.encrypt(src=ALICE)\n",
    "    \n",
    "    # Note that layer parameters are encrypted:\n",
    "    crypten.print(\"Weights:\\n\", layer_enc.weight.share)\n",
    "    crypten.print(\"Bias:\\n\", layer_enc.bias.share, \"\\n\")\n",
    "    \n",
    "    # Load and encrypt data\n",
    "    data_enc = crypten.load_from_party(toy_data_file, src=BOB)\n",
    "    \n",
    "    # Apply the encrypted layer (linear transformation):\n",
    "    result_enc = layer_enc.forward(data_enc)\n",
    "    \n",
    "    # Decrypt the result:\n",
    "    result = result_enc.get_plain_text()\n",
    "    \n",
    "    # Examine the result\n",
    "    crypten.print(\"Decrypted result:\\n\", result)\n",
    "        \n",
    "forward_single_encrypted_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the application of the encrypted linear layer on the encrypted data produces an encrypted result, which we can then decrypt to get the values in plaintext.\n",
    "\n",
    "Let's look at a second linear transformation, to give a flavor of how accuracy is preserved even when the data and the layer are encrypted. We'll look at a uniform scaling transformation, in which all tensor elements are multiplied by the same scalar factor. Again, we'll assume Alice has the layer and the rank 0 process, and Bob has the data and the rank 1 process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a linear layer with random weights\n",
    "layer_scale = nn.Linear(3, 3)\n",
    "\n",
    "# Construct a uniform scaling matrix: we'll scale by factor 5\n",
    "factor = 5\n",
    "layer_scale._parameters['weight'] = torch.eye(3)*factor\n",
    "layer_scale._parameters['bias'] = torch.zeros_like(layer_scale._parameters['bias'])\n",
    "\n",
    "# Save the plaintext layer\n",
    "layer_scale_file = \"/tmp/tutorial5_layer_alice2.pth\"\n",
    "crypten.save(layer_scale, layer_scale_file)\n",
    "temp_files.append(layer_scale_file)\n",
    "\n",
    "# Construct some toy data\n",
    "features = 3\n",
    "examples = 2\n",
    "toy_data = torch.ones(examples, features)\n",
    "\n",
    "# Save the plaintext toy data\n",
    "toy_data_file = \"/tmp/tutorial5_data_bob2.pth\"\n",
    "crypten.save(toy_data, toy_data_file)\n",
    "temp_files.append(toy_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"<ipython-input-15-1916e6c101c7>\", line 6, in forward_scaling_layer\n",
      "    layer = crypten.load_from_party(layer_scale_file, src=ALICE)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/__init__.py\", line 291, in load_from_party\n",
      "    result = load_closure(f, **kwargs)\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tutorial5_layer_alice2.pth'\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"<ipython-input-15-1916e6c101c7>\", line 6, in forward_scaling_layer\n",
      "    layer = crypten.load_from_party(layer_scale_file, src=ALICE)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/__init__.py\", line 310, in load_from_party\n",
      "    result = comm.get().broadcast_obj(None, src)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/communicator/communicator.py\", line 223, in logging_wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/communicator/distributed_communicator.py\", line 313, in broadcast_obj\n",
      "    dist.broadcast(size, src, group=group)\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\", line 855, in broadcast\n",
      "    work.wait()\n",
      "RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:575] Connection closed by peer [127.0.1.1]:36775\n",
      "ERROR:root:One of the parties failed. Check past logs\n"
     ]
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def forward_scaling_layer():\n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    # Load and encrypt the layer\n",
    "    layer = crypten.load_from_party(layer_scale_file, src=ALICE)\n",
    "    layer_enc = crypten.nn.from_pytorch(layer, dummy_input=torch.empty((1,3)))\n",
    "    layer_enc.encrypt(src=ALICE)\n",
    "    \n",
    "    # Load and encrypt data\n",
    "    data_enc = crypten.load_from_party(toy_data_file, src=BOB)   \n",
    "\n",
    "    print(\"Dataaa encrypt\", data_enc)\n",
    "    # Note that layer parameters are (still) encrypted:\n",
    "    crypten.print(\"Weights:\\n\", layer_enc.weight.share)\n",
    "    crypten.print(\"Bias:\\n\\n\", layer_enc.bias.share)\n",
    "\n",
    "    # Apply the encrypted scaling transformation\n",
    "    result_enc = layer_enc.forward(data_enc)\n",
    "\n",
    "    # Decrypt the result:\n",
    "    result = result_enc.get_plain_text()\n",
    "    crypten.print(\"Plaintext result:\\n\", (result))\n",
    "        \n",
    "z = forward_scaling_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting plaintext tensor is correctly scaled, even though we applied the encrypted transformation on the encrypted input! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Neural Networks\n",
    "Let's now look at how the encrypted input moves through an encrypted multi-layer neural network. \n",
    "\n",
    "For ease of explanation, we'll first step through a network with only two linear layers and ReLU activations. Again, we'll assume Alice has a network and Bob has some data, and they wish to run encrypted inference. \n",
    "\n",
    "To simulate this, we'll once again generate some toy data and train Alice's network on it. Then we'll encrypt Alice's network, Bob's data, and step through every layer in the network with the encrypted data. Through this, we'll see how the computations get applied although the network and the data are encrypted.\n",
    "\n",
    "### Setup\n",
    "As in Tutorial 3, we will first generate 1000 ground truth samples using 50 features and a randomly generated hyperplane to separate positive and negative examples. We will then modify the labels so that they are all non-negative. Finally, we will split the data so that the first 900 samples belong to Alice and the last 100 samples belong to Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "features = 50\n",
    "examples = 1000\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Generate toy data and separating hyperplane\n",
    "data = torch.randn(examples, features)\n",
    "w_true = torch.randn(1, features)\n",
    "b_true = torch.randn(1)\n",
    "labels = w_true.matmul(data.t()).add(b_true).sign()\n",
    "\n",
    "# Change labels to non-negative values\n",
    "labels_nn = torch.where(labels==-1, torch.zeros(labels.size()), labels)\n",
    "labels_nn = labels_nn.squeeze().long()\n",
    "\n",
    "# Split data into Alice's and Bob's portions:\n",
    "data_alice, labels_alice = data[:900], labels_nn[:900]\n",
    "data_bob, labels_bob = data[900:], labels_nn[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Alice's network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AliceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AliceNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(50, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Loss: 0.24704287946224213\n",
      "Epoch 199 Loss: 0.08965437859296799\n",
      "Epoch 299 Loss: 0.05166155472397804\n",
      "Epoch 399 Loss: 0.0351078175008297\n",
      "Epoch 499 Loss: 0.026072407141327858\n"
     ]
    }
   ],
   "source": [
    "# Train and save Alice's network\n",
    "model = AliceNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(500):  \n",
    "    #forward pass: compute prediction\n",
    "    output = model(data_alice)\n",
    "    \n",
    "    #compute and print loss\n",
    "    loss = criterion(output, labels_alice)\n",
    "    if i % 100 == 99:\n",
    "        print(\"Epoch\", i, \"Loss:\", loss.item())\n",
    "    \n",
    "    #zero gradients for learnable parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #backward pass: compute gradient with respect to model parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    #update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "sample_trained_model_file = '/tmp/tutorial5_alice_model.pth'\n",
    "torch.save(model, sample_trained_model_file)\n",
    "temp_files.append(sample_trained_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping through a Multi-layer Network\n",
    "\n",
    "Let's now look at what happens when we load the network Alice's has trained and encrypt it. First, we'll look at how the network structure changes when we convert it from a PyTorch network to CrypTen network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 5 \tModule: Linear encrypted module\n",
      "Name: 6 \tModule: ReLU encrypted module\n",
      "Name: output \tModule: Linear encrypted module\n"
     ]
    }
   ],
   "source": [
    "# Load the trained network to Alice\n",
    "model_plaintext = crypten.load(sample_trained_model_file, model_class=AliceNet, src=ALICE)\n",
    "\n",
    "# Convert the trained network to CrypTen network \n",
    "private_model = crypten.nn.from_pytorch(model_plaintext, dummy_input=torch.empty((1, 50)))\n",
    "# Encrypt the network\n",
    "private_model.encrypt(src=ALICE)\n",
    "\n",
    "# Examine the structure of the encrypted CrypTen network\n",
    "for name, curr_module in private_model._modules.items():\n",
    "    print(\"Name:\", name, \"\\tModule:\", curr_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the encrypted network has 3 modules, named '5', '6' and 'output', denoting the first Linear layer, the ReLU activation, and the second Linear layer respectively. These modules are encrypted just as the layers in the previous section were. \n",
    "\n",
    "Now let's encrypt Bob's data, and step it through each encrypted module. For readability, we will use only 3 examples from Bob's data to illustrate the inference. Note how Bob's data remains encrypted after each individual layer's computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Select only the first three examples in Bob's data for readability\n",
    "data = data_bob[:3]\n",
    "sample_data_bob_file = '/tmp/tutorial5_data_bob3.pth'\n",
    "torch.save(data, sample_data_bob_file)\n",
    "temp_files.append(sample_data_bob_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "tensor([[ 0.1100, -0.6804,  2.0982, -0.5902, -1.3748, -1.5008, -0.3524,  0.9976,\n",
      "         -0.8391,  0.3145, -0.2193, -0.9250,  0.2390, -1.7713,  0.3441, -0.7271,\n",
      "          0.6605,  0.6532, -1.0875, -1.0531, -0.0211,  0.2901, -0.0791, -1.2713,\n",
      "         -0.5828, -0.8351, -0.5158, -1.2723,  0.4020,  1.2814, -1.0369,  1.2441,\n",
      "         -1.4441,  0.2607,  1.2759,  0.0963, -0.1713, -0.5385, -1.4254, -0.5076,\n",
      "         -0.3589,  0.0093, -0.3075,  1.1037,  0.5525,  1.4381, -0.7857, -1.4391,\n",
      "          0.2253, -0.0190],\n",
      "        [ 0.4046,  0.6219,  0.8617,  0.6600, -1.4676, -0.3592, -0.1451,  0.1817,\n",
      "          1.6596, -0.4824,  0.4237, -0.4701, -0.8239, -0.3656,  0.2227, -0.3053,\n",
      "          0.2618,  1.9131, -0.4742,  1.5438,  0.1587, -0.8272, -0.2328,  2.6705,\n",
      "          0.1701,  0.3898,  1.3335,  1.3909, -0.8939,  0.3604,  0.5622, -0.2678,\n",
      "         -0.3312, -0.4675, -0.2644,  0.3889,  2.7730, -0.2014, -0.9165,  1.1523,\n",
      "         -0.5984, -2.1399,  1.8487,  0.4516, -0.5944, -0.8262,  1.7124,  1.4091,\n",
      "          0.0822, -1.8511],\n",
      "        [-0.5742,  1.1106, -1.3929, -2.6684, -0.7431,  0.9311, -0.7103,  0.0191,\n",
      "         -2.0803,  3.2108, -0.4232, -0.0904, -1.0918,  1.0201, -0.4553,  0.4050,\n",
      "          0.4642,  0.0553,  0.5706,  1.1879, -0.4623,  0.3766, -0.0145,  1.6251,\n",
      "          0.6308,  0.8590,  1.3428, -0.4418,  1.0405, -0.7612,  0.8228, -0.4961,\n",
      "          0.6267, -0.5249,  0.2891,  0.1279,  0.1657,  1.7779, -1.4608, -1.1891,\n",
      "         -0.2852,  0.9052,  0.5881,  0.2986,  0.2536,  1.2658,  0.3065,  0.3713,\n",
      "          0.8625,  0.8120]])\n",
      "Get attribute forward\n",
      "tensor([[ 0.1100, -0.6804,  2.0982, -0.5902, -1.3748, -1.5008, -0.3524,  0.9976,\n",
      "         -0.8391,  0.3145, -0.2193, -0.9250,  0.2390, -1.7713,  0.3441, -0.7271,\n",
      "          0.6605,  0.6532, -1.0875, -1.0531, -0.0211,  0.2901, -0.0791, -1.2713,\n",
      "         -0.5828, -0.8351, -0.5158, -1.2723,  0.4020,  1.2814, -1.0369,  1.2441,\n",
      "         -1.4441,  0.2607,  1.2759,  0.0963, -0.1713, -0.5385, -1.4254, -0.5076,\n",
      "         -0.3589,  0.0093, -0.3075,  1.1037,  0.5525,  1.4381, -0.7857, -1.4391,\n",
      "          0.2253, -0.0190],\n",
      "        [ 0.4046,  0.6219,  0.8617,  0.6600, -1.4676, -0.3592, -0.1451,  0.1817,\n",
      "          1.6596, -0.4824,  0.4237, -0.4701, -0.8239, -0.3656,  0.2227, -0.3053,\n",
      "          0.2618,  1.9131, -0.4742,  1.5438,  0.1587, -0.8272, -0.2328,  2.6705,\n",
      "          0.1701,  0.3898,  1.3335,  1.3909, -0.8939,  0.3604,  0.5622, -0.2678,\n",
      "         -0.3312, -0.4675, -0.2644,  0.3889,  2.7730, -0.2014, -0.9165,  1.1523,\n",
      "         -0.5984, -2.1399,  1.8487,  0.4516, -0.5944, -0.8262,  1.7124,  1.4091,\n",
      "          0.0822, -1.8511],\n",
      "        [-0.5742,  1.1106, -1.3929, -2.6684, -0.7431,  0.9311, -0.7103,  0.0191,\n",
      "         -2.0803,  3.2108, -0.4232, -0.0904, -1.0918,  1.0201, -0.4553,  0.4050,\n",
      "          0.4642,  0.0553,  0.5706,  1.1879, -0.4623,  0.3766, -0.0145,  1.6251,\n",
      "          0.6308,  0.8590,  1.3428, -0.4418,  1.0405, -0.7612,  0.8228, -0.4961,\n",
      "          0.6267, -0.5249,  0.2891,  0.1279,  0.1657,  1.7779, -1.4608, -1.1891,\n",
      "         -0.2852,  0.9052,  0.5881,  0.2986,  0.2536,  1.2658,  0.3065,  0.3713,\n",
      "          0.8625,  0.8120]])\n",
      "========================\n",
      "tensor([[ 0.1100, -0.6804,  2.0982, -0.5902, -1.3748, -1.5008, -0.3524,  0.9976,\n",
      "         -0.8391,  0.3145, -0.2193, -0.9250,  0.2390, -1.7713,  0.3441, -0.7271,\n",
      "          0.6605,  0.6532, -1.0875, -1.0531, -0.0211,  0.2901, -0.0791, -1.2713,\n",
      "         -0.5828, -0.8351, -0.5158, -1.2723,  0.4020,  1.2814, -1.0369,  1.2441,\n",
      "         -1.4441,  0.2607,  1.2759,  0.0963, -0.1713, -0.5385, -1.4254, -0.5076,\n",
      "         -0.3589,  0.0093, -0.3075,  1.1037,  0.5525,  1.4381, -0.7857, -1.4391,\n",
      "          0.2253, -0.0190],\n",
      "        [ 0.4046,  0.6219,  0.8617,  0.6600, -1.4676, -0.3592, -0.1451,  0.1817,\n",
      "          1.6596, -0.4824,  0.4237, -0.4701, -0.8239, -0.3656,  0.2227, -0.3053,\n",
      "          0.2618,  1.9131, -0.4742,  1.5438,  0.1587, -0.8272, -0.2328,  2.6705,\n",
      "          0.1701,  0.3898,  1.3335,  1.3909, -0.8939,  0.3604,  0.5622, -0.2678,\n",
      "         -0.3312, -0.4675, -0.2644,  0.3889,  2.7730, -0.2014, -0.9165,  1.1523,\n",
      "         -0.5984, -2.1399,  1.8487,  0.4516, -0.5944, -0.8262,  1.7124,  1.4091,\n",
      "          0.0822, -1.8511],\n",
      "        [-0.5742,  1.1106, -1.3929, -2.6684, -0.7431,  0.9311, -0.7103,  0.0191,\n",
      "         -2.0803,  3.2108, -0.4232, -0.0904, -1.0918,  1.0201, -0.4553,  0.4050,\n",
      "          0.4642,  0.0553,  0.5706,  1.1879, -0.4623,  0.3766, -0.0145,  1.6251,\n",
      "          0.6308,  0.8590,  1.3428, -0.4418,  1.0405, -0.7612,  0.8228, -0.4961,\n",
      "          0.6267, -0.5249,  0.2891,  0.1279,  0.1657,  1.7779, -1.4608, -1.1891,\n",
      "         -0.2852,  0.9052,  0.5881,  0.2986,  0.2536,  1.2658,  0.3065,  0.3713,\n",
      "          0.8625,  0.8120]])\n",
      "Get attribute forward\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([[ 4049621643375310673, -7930101051482060499,  1057267294055947527,\n",
      "          4505101025399592356, -1979998744574996526,  4900917069261613794,\n",
      "          2597517065469092886,  8957316956076165945, -7585434739815188529,\n",
      "         -8965496182622527742,  8599085550746645348, -4105957789101543181,\n",
      "          4020145202421828743, -5528783094952548870,  1605858196870720014,\n",
      "         -6590952368082056462,  5423706150329539953,  6524020199698834500,\n",
      "          2330058009649747097, -4231315218613975963],\n",
      "        [-4876831932703037810, -3106561068842937946, -8769590410951622339,\n",
      "         -5442872509995169036, -4363874314934158445,  9097036862009623366,\n",
      "          3830446845471485644, -8385657828064941957, -8339293269908472717,\n",
      "          6741270749084754625,  -124671937907458001, -2915790217997477030,\n",
      "         -7337848525884546968,  5469335748993467940,  -507282120907920621,\n",
      "         -6480051264720607903, -8279929710257070860,  1170581918088109620,\n",
      "         -2083613309766415073, -6862297387864860384],\n",
      "        [ 7079823959044908671,   783561178141734543, -7566651120921175147,\n",
      "          -332947757174375409, -6868493347037311120,  3285926305485694273,\n",
      "          8806655827675370455, -7525445833579793915,  5542824201286681259,\n",
      "           870897242471462040,   649584293066654106,  7017568483404217539,\n",
      "         -9098432562638517545,  4764064697016904537,   937498361227236087,\n",
      "          -568258596858617183,  1464706177069376675,  6364267935533653045,\n",
      "          7841942215128382774,  5438265036223713325],\n",
      "        [-3792592186640818783, -9074765116549538668,  5629805957502469159,\n",
      "          1795417380442443739, -5288735435008292145,  7241059274351934492,\n",
      "          7950063156277011721, -4429275100252747360, -2627024731176978588,\n",
      "         -1235768164905059213,  8881599310959203311,  1892210648262407974,\n",
      "          5156392081738539956,  -780480851123982569, -8298451853968923763,\n",
      "         -5898065263709507594,  3323786583381586055,  7334597939277633592,\n",
      "            83784909145498029,  8899098980187076268],\n",
      "        [ 4348096543215895489,  5612981490069780421, -8195346886489212831,\n",
      "          5624547591081376326, -3592314054277794247, -6158187573691189717,\n",
      "          2757781893342461659, -6235799127346105239, -5411931604444040277,\n",
      "         -1943282907908928020, -1070686199321643683,  4738733880682360960,\n",
      "          4627239472148693717, -3996855006833469218, -7732579824837853483,\n",
      "         -7620143033144787194,  6933888759140464930, -6117205310898067907,\n",
      "         -2442772960537098872, -7806454759265062566],\n",
      "        [ 2200970427607651852,  4987805279452315222,  3358554640623171163,\n",
      "          1190203217557449036, -8934489648688344870,  4903057792800195485,\n",
      "          8709793620174739947, -7916762114498065159, -2072853269743642009,\n",
      "         -5582814809670326588, -2128155190424114831, -7836646084378906018,\n",
      "          4192712614094086142, -6644515183568869000,  5100804856967058761,\n",
      "          1154279336953499902, -6482753646602383081,  8136301774817635716,\n",
      "          3389235530108548301, -6244510303410169990],\n",
      "        [-5264923657540142534,  2824423067876339329,  -729563276414813576,\n",
      "          2077597463361629362,  2794709526297561157, -3528677330357476680,\n",
      "          3723287956070646566,   215058053984251912,  6775162501717696502,\n",
      "         -8072157834218727549, -4512570874201575130,  5911649398276967701,\n",
      "          5594001837297396250,  6552669021461471279,  1412442483531812992,\n",
      "          1259684330845658466,  4186432477850913390,  3775594238679447405,\n",
      "         -8059633531956021213, -5540483179940112507],\n",
      "        [ -953345295557676028,  6015513387253765654, -7239042730730544289,\n",
      "          2051095937611955438,  8771259018121231284,  2094169232901978622,\n",
      "         -6968959461701928255,   536350130059166667,  3673286511428582254,\n",
      "         -2948459503221613685,  2261081088229017450,  1487669846948205235,\n",
      "          5297427625550242969,  3397822601450299211,  1469552543239619815,\n",
      "         -6073353096032045455, -4645911591080666063,  -352579360970501987,\n",
      "         -6458225905135495768, -6720280340824388310],\n",
      "        [ 8517343727251042757,  -139065535436081229,  1759110390799121204,\n",
      "         -5272285573159000044, -1952506443719755814,  2702661335000045692,\n",
      "          2417105893155768140,  -124316690666375157, -4062316356676433842,\n",
      "          5257976555071280198, -4165558797378540538, -5711302112817105542,\n",
      "          -485918020680245326,  1581000870468813454, -3922781665149840879,\n",
      "         -8545453020426060489,  7685946611410521355, -1915456685701385707,\n",
      "          2093814113557888874,  6666997004136962650],\n",
      "        [-5744176230685850657,  7105560677558667704, -8222694993761850104,\n",
      "         -7161485785557617649,   791603217686728758,  8073234054828314332,\n",
      "         -6697335183227963520, -8272510222204204589, -3503147914264921500,\n",
      "          4220482774061347436, -7992191607717273592, -4787867841899534707,\n",
      "          1739394975695368519, -3858274714842057043,  1724804971567172031,\n",
      "           934450845901489862, -8771164754136394217,  3607815064849593591,\n",
      "         -4153255508344393260,  5489170022495296950],\n",
      "        [ 5059799626625150752, -4018419957463665936,  8290649129793943609,\n",
      "           897005669337018610, -1384288097808091009,  6116499113396015007,\n",
      "         -4418922413453833509,  1271393438394555414, -3104621471055309090,\n",
      "         -2993428741403197854,  6392592840450191182, -7316842984762442828,\n",
      "          8353768518424348706,    -8755026304200731,  7958222844869226211,\n",
      "          5324032371224137315, -6165900992577401450, -3156228179727080358,\n",
      "          1298596614228355084,  5061331658918790629],\n",
      "        [-1802020044079025714,   343778698498644035,  3159395575798127903,\n",
      "         -3727370772984617619,  3807879696976378785, -6514189372512169393,\n",
      "         -5439540574163051690,  -861678929843728567, -1433643434180196382,\n",
      "         -5094117382685913300,  4206753408962258329,  1698752178373593108,\n",
      "          3776169503017172079, -5178958621628106224, -4084075470127084854,\n",
      "          8298115243334167594, -5761137055731703387, -6756610556186681819,\n",
      "         -2094848076619343963,  2457378252774153246],\n",
      "        [ 3151060364810099208,  3707075866442283803,   135433349445004357,\n",
      "          7978604797186951840,  8788857442094374606, -5622861341412579104,\n",
      "         -8280126003609828898, -2507978914183214040, -7028845855940285950,\n",
      "          -446686375874425309, -1519619800423084362,  6055073243793598814,\n",
      "         -6553497567996523757, -5662955957137946889, -4040731517525578023,\n",
      "         -2832509464494404951,  6726715932622223328, -6241803335533748271,\n",
      "         -4379048376978360640,  3406433108184096428],\n",
      "        [ 5574887206633251508,  4668297088407172854, -6755796501449796605,\n",
      "          5638319751820306632,  -272347581222112600, -8402483745834788118,\n",
      "         -6400192840025384464, -7029539428486503114,  8499147541546915009,\n",
      "           256138704924596891,  1400978258840114277, -1345904730757770837,\n",
      "          4053061447368833873, -4849585514068877194,  3658408054337285428,\n",
      "          9162373730170692136,  1003409750783976145,  5573549515180994740,\n",
      "          2774138968533895020, -6410766007994431220],\n",
      "        [ 2285966041694882726,  6088865580633788991, -3100169037229029572,\n",
      "         -4360825891147562527, -1201025728934041728, -3323844826170037676,\n",
      "          3860953968784143458, -1934925740318311278, -2687760934242673642,\n",
      "         -6799755389201164848, -6225058113978796133,  1125886707012985491,\n",
      "         -2285404089305664667, -1212964470582653313, -5101376127383651515,\n",
      "         -8816428446054669473, -6926685119686782696,  5911518042757604121,\n",
      "         -9106946512584493026,  1454185375550051138],\n",
      "        [  871830024799017415, -6927808415567783979, -2217834489795457012,\n",
      "          3686627023652729353, -8641881540012631295,  5664993079619616098,\n",
      "           -11321250521685905, -6584240857069258802,  -123912050477589350,\n",
      "          2446581728484376869,  7740249672561260024,  6131197306864044291,\n",
      "          2003532343597976780,  8529858119616361578, -8821982808672488400,\n",
      "         -6780668128973597750, -6962527185627866919, -2259904921608864522,\n",
      "         -3267319720141627475,  -483883619327175579],\n",
      "        [ 1664067698734998660, -5438413113388558953,   114263778615802749,\n",
      "         -8468130232588449801, -9161102024062427558, -1037764378603544570,\n",
      "          3201610995076282341,  2878843965929104731, -1918224261832445354,\n",
      "         -5087662097033792069,  7998337521722061536, -4172561959441090639,\n",
      "          7679048459908120089,  7185457518424444511,  8799764001898652513,\n",
      "           806244725613365319,  2512046993578616397,  6888980170464124975,\n",
      "         -3004995939317432929, -8040720496021103031],\n",
      "        [ 7640561066326171694, -6710259425573368866,  1533416234573669270,\n",
      "         -8842837292693766915, -9174212240539965017,  3232487333999580745,\n",
      "          6333918664946579005, -2407368606877908017, -8504542366401619604,\n",
      "          7097417211861267987,  3203708813332575783,     3602260818241952,\n",
      "          9198463643203188233,   123438718394217251,  6875557647816686491,\n",
      "          5554860000849622592,  -360823675506040566, -5729239555515229600,\n",
      "         -7570363495982215981, -1730868145333851625],\n",
      "        [-1198267094046472837,  9211871037380287836,  7630297264267757511,\n",
      "          8257884132102764920,  7502575841555267515, -3322178998259760936,\n",
      "           303032168910402914,  7509818460691419517,  2203042558990592224,\n",
      "          2738838113191386154,   348047864767219662, -7263622927150712129,\n",
      "          2099001691395393966, -3514732589224981561,  1059424150889753290,\n",
      "          -823387445298600085, -7722430976087588097, -2877241036036360750,\n",
      "          6734028628711867049, -6137062647064630708],\n",
      "        [ 7980763840906129154, -5158010137481484409, -8880521668644857768,\n",
      "          3471730662018819269,  6169847710731793900,   175016032724576736,\n",
      "         -5789409139377446134,  6330279644048839936,  4601567086388896586,\n",
      "          -285909758107886123, -6311902017661252191,   171752419167679754,\n",
      "         -8007372946672727198,  5824059635372194559, -1646620772917542728,\n",
      "          -870231174129754300, -5981125346727411493, -5991093816489817651,\n",
      "          2919044177896102998,  -125588372118150896],\n",
      "        [ 3246534542844426062,  7987757889375085197,   670895465703262189,\n",
      "           -14004587257575615,  3512874416880065394,  7554676233475064067,\n",
      "         -6312461216244280906,  4871488515387024008,  3397193830236604223,\n",
      "          7431453889075621391,  6049284479493028072,  7969084920679933736,\n",
      "         -1724555980706635384, -2747311981295340880,   978758427590218747,\n",
      "         -2502900030036059651,  4416439053442288474, -5639626587153769678,\n",
      "         -5841826524270181085,  1644535514114657626],\n",
      "        [ 8901665816634946558,  3390180275555501970, -7119399993751194662,\n",
      "         -6500848905753477726,  9017641129816712085,  -160597446155239228,\n",
      "           828711576616695350, -6353038651946286987, -4251958405138409008,\n",
      "          8002145631572539973,  2829084447389227153, -4590224135039257821,\n",
      "          6141404809444668914, -7363505812932713370,  4057527531173773235,\n",
      "           564765246271516946,   735354108299920742,  4492946596460961953,\n",
      "          3833288915019873376,  1633093870469360199],\n",
      "        [ 3096321228258167009,  1171078095124641260, -1182833337450905622,\n",
      "          8092057382312283851,  1986545372989685387,  3146191694487924060,\n",
      "         -5609170999645338896, -2838589757622388404, -6930844655112811179,\n",
      "         -4904157101124926841,   413195842054422676, -7411999533332392119,\n",
      "            91421627942537978,  6788268450090399333, -5750196517001960509,\n",
      "         -3028487316553104432, -4614517169066607081, -3589421808265194712,\n",
      "         -5205054376733766466,  5939436839656534120],\n",
      "        [  955498825716505157,  8742431965319018253,  8435303285417478774,\n",
      "          5607554543070037430,   121411563924664286,  8530766972646221307,\n",
      "         -8210119587282026926,  2528074068106644252, -4725248064326554097,\n",
      "         -4063542483808376553,  1196904440037795793,  -257731180553925881,\n",
      "         -9003482059487281776,  5147443852922962932,  5585361001912874321,\n",
      "         -4929359099781066693, -6895265642449803734, -1318506772258337253,\n",
      "         -9158933136781524567,  5005154320728690589],\n",
      "        [ 7921138440328666082,  5725677604287491466,  8631257697586936564,\n",
      "          3710481243734075444, -2698126590502536782, -4750502255774548316,\n",
      "          8760655019022519516,  5552522152491074976,  5222084412696652904,\n",
      "          8927964718644097156,  6937682844795521629,  -350384347315768152,\n",
      "           465428159829328667, -8893772469101899525,  8224758675935130245,\n",
      "          -903887265390770620, -7847180187450434412,  7524172328008933806,\n",
      "         -6749118976185485369, -8660112862282145724],\n",
      "        [  190658950294773957, -1707338501291952213,  1589612732858252543,\n",
      "         -1905067327945277929, -3590105940216094013, -3069019493573291192,\n",
      "         -1220668712536457357,  6002399923623367266,  1388861086361824077,\n",
      "         -4014149806120096012, -4204920735773251106,  5132121800879222538,\n",
      "          -134903385172624640,  -308577127372835117,  1137181811110445221,\n",
      "         -4480203466490335729, -3929597149448609279, -5620070400002456313,\n",
      "         -7925899347186632187,  -380797062681659298],\n",
      "        [ -384230305013044339,  3707108391822377518,   136238268131536217,\n",
      "         -6611363138838091332,  3175533455578889213,  5303047717553603316,\n",
      "         -5100912301398729525, -4594732522675610931,  3561972018393017272,\n",
      "         -6914692015148753051, -8123254150916424590,  5828615005731917518,\n",
      "         -2870138684126548981,  3332921374338510453,  8622176090539386989,\n",
      "         -2269590695593331195, -3059530066723707301,  3200068751426508440,\n",
      "          6242880926497275646, -1206013960657443857],\n",
      "        [ -897753534172891371, -6026186658460866760,  6275391647377727668,\n",
      "         -2028175511107751443,   861017909823093127,  3062166583414878702,\n",
      "           784172808121330423,  5145444230771501559,  3265482981092349999,\n",
      "          -457436711997983204, -7059285552158919842, -6792363364974750801,\n",
      "         -6723877520452823125,    49513597429025350, -5164037053659983178,\n",
      "         -7827477076500426014,  6152883832987042418,  7655163966954920657,\n",
      "           -10152092230997382,  2400403273402879990],\n",
      "        [-4522644822782925092,  7497241971278830625,    46247083060333481,\n",
      "          6424810050278549930,  1838710781581960030, -3271120454908139417,\n",
      "          3598971713657911342, -2011534924104080787, -7278112731386458538,\n",
      "          9070337044889247329,  1522140835537882063, -8168876062219847365,\n",
      "          9121050801154431014, -1869010834478721027, -1874456830531253381,\n",
      "          4544207262490127324, -5087761088833124368,  6328626340226840955,\n",
      "         -7769973328954169240,  -354739936415470723],\n",
      "        [ 5023077148257097669, -9142045540918418454, -8124368404573127464,\n",
      "         -1309367557477849389,  5397493417492376727,  2571186754771948366,\n",
      "         -7155467189904492237, -1725094144550775845,  3953636715082709109,\n",
      "          9081768812789275454,  1202924933255704884, -5980149064305640290,\n",
      "          5347393046887226010, -9165815997248625053,  -989472094204842471,\n",
      "          5920606552462017014, -2573604071135082199,  4332599775569072644,\n",
      "         -7027753541655192847, -5887346597856060907],\n",
      "        [ 3072232718195434415, -7979626898752076624,  -465534359703398797,\n",
      "         -9006481542481393121, -6256578801946532676, -5873268712602419646,\n",
      "          9084495113688476194,  8004868074680627982,  8773065499861171327,\n",
      "          9021091821932518082, -2671625638389271427, -2216868032394929037,\n",
      "          2740154731740379655,  3360717705325831763,  7923929540841704842,\n",
      "         -8116318424363052787,  1153586551129995980, -2523308750451649379,\n",
      "         -4844920406879824908, -6443921710529404268],\n",
      "        [ 8252620037809560604,  1257836974547603659, -7396681426507076902,\n",
      "         -1187581913760566279, -3439779390112720654, -2428106878027673938,\n",
      "          3301087097051503897,  8321462126514003787,  9039035549847772437,\n",
      "          6617485706818125653,  8508299050937773092, -8232794090757429966,\n",
      "           330014019587444119, -2459813878351701679, -5708577894980283622,\n",
      "          5151203305215893477,  2697151772340377871,  8317500622030084373,\n",
      "          7890693063361929676,  7458533667935495761],\n",
      "        [ -425106961942583705,  -649213913224453330,   150395228327421547,\n",
      "          7357543830375376388, -1500616659331390027,  4838302666920250580,\n",
      "         -1918038733103851591, -8485224577146607715,  8917356440794263691,\n",
      "          1305576943086260170, -5528890363833638477,  6762141482675946645,\n",
      "          9026868476831394115, -5840279297063635239,  9066739242496079297,\n",
      "         -7104092284985772613, -2318934226290794168,  6556348858495998293,\n",
      "          1079320520328866037, -4222262690078236325],\n",
      "        [-6413338262059928792, -6432336869115761144,  9029255160147190300,\n",
      "         -6712518494034827482, -7309553270851228064,   719765795907511174,\n",
      "          7513754457853408597,   958897967925020786,  5215650165703983834,\n",
      "          1477871788379289808,  4731825597781177529, -6164780856012748173,\n",
      "         -4324779761825540069, -3948076389252550764, -1457075968923824490,\n",
      "         -9183283457641621293, -7035755262283333327,  1864552537477779916,\n",
      "          -208626188904572439,  -648392306111757446],\n",
      "        [-1742314276632272967, -6262511400905162723,  6957657787725910582,\n",
      "          -555206913439459514,  4919176874386830713, -2706136903913752198,\n",
      "         -7579289863236277705, -6689264427383954040,  7109639171331767632,\n",
      "         -4238377419266762864, -6640390665044874225,  3501092941290046168,\n",
      "          5303523680958201394,  5030131646692012606, -7867899537168793289,\n",
      "         -3504634287924976915,  1427989359261189769, -8639584594163766015,\n",
      "          2655989754083353277,  1763664808274903092],\n",
      "        [-4625090628410455225,  1551823184564306916,   272548831345294208,\n",
      "         -8058035107573593450,  4109222861171464914, -2183495808364485367,\n",
      "         -1025091435718007134, -3571317447199150112,  4294585937179256401,\n",
      "          -652264404836784940,  9134054107274601802,  -164050966537417745,\n",
      "         -8133881697850093256,  -410014187061665859, -7206669137554237958,\n",
      "          9170160694968444362, -2351668681202812642,  6674785925692982127,\n",
      "          2288537026666878280, -8361608753750522295],\n",
      "        [ 2970927040035242513,   102064214380546585, -2550065647906668616,\n",
      "         -3945587656168859473, -1433118762913725519,    -9394575094231691,\n",
      "         -4697850800321769624, -9190572223261561254,  3163158741763055139,\n",
      "          3586191571034586133, -2641169863125608123, -7094595763228787045,\n",
      "         -2001605455582822263, -2587819944803241746, -6598117717172273429,\n",
      "         -1501581216732053550, -2470554850243273622,  4382224691017282753,\n",
      "           265338176479220651,  7707947569525085021],\n",
      "        [  448973440237515142,  5668481434067468922, -6556370846405445333,\n",
      "          4359991501281899584,  7723860711682159189, -1999393600559402692,\n",
      "         -8065339678443364670,  6253047182964479184, -1608393183550410242,\n",
      "           894163073599669345,  7398081314073581992, -1294175717407585136,\n",
      "         -5327663804187106776,  5057762781288215254, -5531645269736872402,\n",
      "          9164808187256037008,  5367342647165565045,  8211292552347369198,\n",
      "         -7800300345597248956, -8775582227666452902],\n",
      "        [ 7087538744488903333,    71324593493403980, -5079035098068282677,\n",
      "         -2897371957165496657,  8169243396085377047, -5066416249737565758,\n",
      "          -878153728565761872,  1460199757601893850,  6175523913284637924,\n",
      "          7977550345405956458,  1072203597033766356, -3795166315629909533,\n",
      "          1325825798055651024, -5316356433302415867,   640010069583348101,\n",
      "          5960210806562955934,   192080889111075059,  4178734398310437000,\n",
      "          9145595423490102647, -3852102367022189897],\n",
      "        [-1450498848613435011, -4476351462871299107,  2983227622992334434,\n",
      "         -7019738032153374540, -1660084250843420014,  1663747035042901114,\n",
      "          -846300777164270041,   111862877772813216, -6791724864670612108,\n",
      "         -9216666196725856388,  8238764167305229798,   317458994675106247,\n",
      "          3926722041467181940, -7084335493649728882, -3696111319332935363,\n",
      "          8797237186685762335, -2489950163600937629, -6857294917005523029,\n",
      "          3828181020203211407, -3139583186473419506],\n",
      "        [-6054926890003491753, -8926380962176737503, -5149284032031019020,\n",
      "         -2026905383668566593, -9114954337744282234,  3872589104977052383,\n",
      "          5936069805140836610, -8274430209563298292, -1599837026427921190,\n",
      "         -6384397941621646424,  4728888217283305134,  8241274468487180989,\n",
      "          8474314079711870662, -8819892876572367027, -7381508832730385070,\n",
      "          4381344798507225595, -6204271748461699731, -7400427312031024879,\n",
      "          2554173454353632100,  5277018027172988716],\n",
      "        [-7944376256664651751, -5455844580794101665, -2718917618784375228,\n",
      "         -1446918641108173915,  5095919579428255099,  8610162122745195909,\n",
      "          6653767103405773937,  6964666186680966672, -7678252218668016978,\n",
      "         -6613127722186609585, -5920307568731057764, -2403342501430431616,\n",
      "          6095159482042620932,   -68305334366469861,   358284954415116658,\n",
      "          -816441605961530320, -1596691498230471837,  3098117025366562089,\n",
      "          8584684413267520579,   -70151954822101590],\n",
      "        [ 1331421873457499952, -8564211584904463063, -7966470543710232489,\n",
      "          -936748101064610457,  1689405075828270625, -7684199016821216226,\n",
      "         -3804620734898505535,  1139271244650992004,  2130747957689434695,\n",
      "          3015961184383114980,  1182468933528052000, -8685520121451979175,\n",
      "         -7556840511666878042,  1111827956081720282, -5488079210731636185,\n",
      "          -891170382838386723,  7331539855517529561,  5029142643046438121,\n",
      "          4190357847667287282,  1069495238903822310],\n",
      "        [-4046781561590940826,  9180094415870995821, -4707597590243515206,\n",
      "          -781749822535115550, -8035914767086125270, -3794914767809012718,\n",
      "         -1586702556949962779,   768281437453289499, -6577733879547135100,\n",
      "          1567847805180515849, -8013888204860978070,  -554351596679842372,\n",
      "          4043810229850633546, -5373802535051559610,  6026288967323382555,\n",
      "         -6753465998843329375, -6725861495115807359,  4963730242009084340,\n",
      "          5304438087961241838, -8698357261078059965],\n",
      "        [ 5662398479999552696,  7024714475705632450,  -208176593926117640,\n",
      "           364728868877066291,  3272551269761049906,     9251802087602690,\n",
      "         -1326093198802949162,  2051584500527563695,  5896483512933837963,\n",
      "          1868086579098562237,   567794979396199571,  7797629229272625130,\n",
      "         -1142901938209892532,  6406929267942776932, -6458255166316711800,\n",
      "          7466280600161730929, -1984856538309081490,  7003857852013282012,\n",
      "         -1038508468976396837, -6458171055046884903],\n",
      "        [ 5930971291518059244,  2898398495430269434, -1530849834354832502,\n",
      "          1196160232662672304,  -648054690039572464,  8368100994950464206,\n",
      "          8371960632236365360, -6984205168240187320, -4394913523439750686,\n",
      "          3765643703687784824,  -735910817256528906,  3121095699697356755,\n",
      "         -2456660949664266440,  7987315288959803361, -6252191078072717385,\n",
      "          2828775317575740167,  8446056724744792559,  2074045907389677766,\n",
      "          -764251726910538711,  8005219691960660271],\n",
      "        [ 7495120479645881787,  7287911309769425977, -5810469970878381725,\n",
      "         -8019463442066722827, -3250838741525597056, -5492449808811358285,\n",
      "         -3000949898338942170, -3990665404925608290,  8647370644068084459,\n",
      "         -2833064331704943895, -5357222202002874624, -6928157816118368978,\n",
      "         -4634200095361923459,  5045996685355551509, -5594476441419316840,\n",
      "         -8552334997175936846,  -891044740467146458, -1526307275757312063,\n",
      "          1892135258001368637,  8913580045854206737],\n",
      "        [ 2523958018626433856,  6037449390396444467,  -569987554383734562,\n",
      "         -4232426311378297465,  8449994104415836367,  7961869621551935042,\n",
      "          3960351184223348306,  7916221863774568055,  7467363222375274783,\n",
      "         -3181876863646828207, -1760113463615064855, -6353882072896998385,\n",
      "         -8524838574106274217, -8816905745546583658,  4238663309990608827,\n",
      "         -1210616418622444107,  8209156194855633935,  3700351072225699147,\n",
      "         -3675195929713855326,  7225378140593585932],\n",
      "        [ 4872837479633670236, -7756622149778891854, -1734599136278517659,\n",
      "          7425684759967871801,  1099696189986585529,  -137453477889246669,\n",
      "         -7417840268268152282, -1042124434166746230,   995232035450190407,\n",
      "          1062303894859906583, -1656027546650655350,  1475805116144211409,\n",
      "          -642087968171675572,  9041710781098427229, -5613261361835371533,\n",
      "          5149159337529700965, -8430780005438136955, -3119460160067538858,\n",
      "          4947905885479965867,  1402462229867829093],\n",
      "        [-8651255687754068119,  1580277772518516658, -8142792169031678042,\n",
      "         -6468063964214806585,  -907424654041839625,  4600619370995048239,\n",
      "         -1366986037093693997,  3469195805208576644, -8518981736172302043,\n",
      "            56443503207459579, -6628302999580739601, -4586783482849677604,\n",
      "         -2974304215068826469,  8059620548220144388,  -747352923644234260,\n",
      "          1768558814936962271, -1818465202411962542, -4573476623192342982,\n",
      "         -6979576908458763950,  6406648639289221982]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1100, -0.6804,  2.0982, -0.5902, -1.3748, -1.5008, -0.3524,  0.9976,\n",
      "         -0.8391,  0.3145, -0.2193, -0.9250,  0.2390, -1.7713,  0.3441, -0.7271,\n",
      "          0.6605,  0.6532, -1.0875, -1.0531, -0.0211,  0.2901, -0.0791, -1.2713,\n",
      "         -0.5828, -0.8351, -0.5158, -1.2723,  0.4020,  1.2814, -1.0369,  1.2441,\n",
      "         -1.4441,  0.2607,  1.2759,  0.0963, -0.1713, -0.5385, -1.4254, -0.5076,\n",
      "         -0.3589,  0.0093, -0.3075,  1.1037,  0.5525,  1.4381, -0.7857, -1.4391,\n",
      "          0.2253, -0.0190],\n",
      "        [ 0.4046,  0.6219,  0.8617,  0.6600, -1.4676, -0.3592, -0.1451,  0.1817,\n",
      "          1.6596, -0.4824,  0.4237, -0.4701, -0.8239, -0.3656,  0.2227, -0.3053,\n",
      "          0.2618,  1.9131, -0.4742,  1.5438,  0.1587, -0.8272, -0.2328,  2.6705,\n",
      "          0.1701,  0.3898,  1.3335,  1.3909, -0.8939,  0.3604,  0.5622, -0.2678,\n",
      "         -0.3312, -0.4675, -0.2644,  0.3889,  2.7730, -0.2014, -0.9165,  1.1523,\n",
      "         -0.5984, -2.1399,  1.8487,  0.4516, -0.5944, -0.8262,  1.7124,  1.4091,\n",
      "          0.0822, -1.8511],\n",
      "        [-0.5742,  1.1106, -1.3929, -2.6684, -0.7431,  0.9311, -0.7103,  0.0191,\n",
      "         -2.0803,  3.2108, -0.4232, -0.0904, -1.0918,  1.0201, -0.4553,  0.4050,\n",
      "          0.4642,  0.0553,  0.5706,  1.1879, -0.4623,  0.3766, -0.0145,  1.6251,\n",
      "          0.6308,  0.8590,  1.3428, -0.4418,  1.0405, -0.7612,  0.8228, -0.4961,\n",
      "          0.6267, -0.5249,  0.2891,  0.1279,  0.1657,  1.7779, -1.4608, -1.1891,\n",
      "         -0.2852,  0.9052,  0.5881,  0.2986,  0.2536,  1.2658,  0.3065,  0.3713,\n",
      "          0.8625,  0.8120]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"<ipython-input-12-b83eec178921>\", line 16, in step_through_two_layers\n",
      "    out_enc = private_model._modules['5'].forward(data_enc)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 538, in forward_function\n",
      "    res = object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 1465, in forward\n",
      "    output = x.matmul(self.weight.t())\n",
      "  File \"/home/george/contrib/CrypTen/crypten/cryptensor.py\", line 250, in __torch_function__\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: CrypTen does not support torch function <method 'matmul' of 'torch._C._TensorBase' objects>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPCTensor(\n",
      "\t_tensor=tensor([[-4049621643375321552,  7930101051482064465, -1057267294055944025,\n",
      "         -4505101025399597458,  1979998744575004079, -4900917069261609613,\n",
      "         -2597517065469100112, -8957316956076178308,  7585434739815185470,\n",
      "          8965496182622520963, -8599085550746647627,  4105957789101547983,\n",
      "         -4020145202421827251,  5528783094952541739, -1605858196870704286,\n",
      "          6590952368082060427, -5423706150329526256, -6524020199698833307,\n",
      "         -2330058009649750405,  4231315218613966555],\n",
      "        [ 4876831932703041515,  3106561068842942226,  8769590410951625778,\n",
      "          5442872509995173405,  4363874314934151667, -9097036862009631555,\n",
      "         -3830446845471480148,  8385657828064938669,  8339293269908476596,\n",
      "         -6741270749084761630,   124671937907468563,  2915790217997472794,\n",
      "          7337848525884542453, -5469335748993463031,   507282120907919190,\n",
      "          6480051264720596159,  8279929710257076500, -1170581918088107930,\n",
      "          2083613309766410525,  6862297387864859213],\n",
      "        [-7079823959044910976,  -783561178141741634,  7566651120921155802,\n",
      "           332947757174371619,  6868493347037315019, -3285926305485705010,\n",
      "         -8806655827675368271,  7525445833579784481, -5542824201286681539,\n",
      "          -870897242471471256,  -649584293066658435, -7017568483404213489,\n",
      "          9098432562638521906, -4764064697016907926,  -937498361227221904,\n",
      "           568258596858616117, -1464706177069371717, -6364267935533645648,\n",
      "         -7841942215128376098, -5438265036223714138],\n",
      "        [ 3792592186640824056,  9074765116549532298, -5629805957502469959,\n",
      "         -1795417380442446669,  5288735435008287768, -7241059274351935715,\n",
      "         -7950063156277000340,  4429275100252750990,  2627024731176978001,\n",
      "          1235768164905049709, -8881599310959198493, -1892210648262410215,\n",
      "         -5156392081738535029,   780480851123990197,  8298451853968922094,\n",
      "          5898065263709511291, -3323786583381588374, -7334597939277624941,\n",
      "           -83784909145505914, -8899098980187068268],\n",
      "        [-4348096543215905599, -5612981490069776354,  8195346886489200574,\n",
      "         -5624547591081376457,  3592314054277791770,  6158187573691186756,\n",
      "         -2757781893342462516,  6235799127346100594,  5411931604444047898,\n",
      "          1943282907908929778,  1070686199321639840, -4738733880682352207,\n",
      "         -4627239472148689433,  3996855006833468798,  7732579824837865921,\n",
      "          7620143033144783774, -6933888759140462678,  6117205310898062597,\n",
      "          2442772960537102930,  7806454759265066327],\n",
      "        [-2200970427607658107, -4987805279452317921, -3358554640623176315,\n",
      "         -1190203217557440858,  8934489648688353119, -4903057792800196425,\n",
      "         -8709793620174740670,  7916762114498067072,  2072853269743649180,\n",
      "          5582814809670318439,  2128155190424118157,  7836646084378901843,\n",
      "         -4192712614094093487,  6644515183568871078, -5100804856967056347,\n",
      "         -1154279336953501644,  6482753646602373412, -8136301774817625187,\n",
      "         -3389235530108546826,  6244510303410165773],\n",
      "        [ 5264923657540139800, -2824423067876333342,   729563276414807808,\n",
      "         -2077597463361632963, -2794709526297558172,  3528677330357470984,\n",
      "         -3723287956070633743,  -215058053984251078, -6775162501717699845,\n",
      "          8072157834218737704,  4512570874201580800, -5911649398276970752,\n",
      "         -5594001837297396786, -6552669021461475386, -1412442483531817688,\n",
      "         -1259684330845656705, -4186432477850910260, -3775594238679449192,\n",
      "          8059633531956029668,  5540483179940120839],\n",
      "        [  953345295557671281, -6015513387253773928,  7239042730730554064,\n",
      "         -2051095937611947575, -8771259018121221596, -2094169232901980722,\n",
      "          6968959461701929349,  -536350130059167740, -3673286511428578429,\n",
      "          2948459503221609836, -2261081088229018721, -1487669846948205775,\n",
      "         -5297427625550238884, -3397822601450299845, -1469552543239628183,\n",
      "          6073353096032036788,  4645911591080671155,   352579360970499399,\n",
      "          6458225905135487328,  6720280340824396115],\n",
      "        [-8517343727251037254,   139065535436072583, -1759110390799127448,\n",
      "          5272285573158994629,  1952506443719762265, -2702661335000041970,\n",
      "         -2417105893155772816,   124316690666363429,  4062316356676437986,\n",
      "         -5257976555071283385,  4165558797378537739,  5711302112817113370,\n",
      "           485918020680251424, -1581000870468813213,  3922781665149850131,\n",
      "          8545453020426068577, -7685946611410520811,  1915456685701398746,\n",
      "         -2093814113557894590, -6666997004136970041],\n",
      "        [ 5744176230685849769, -7105560677558670711,  8222694993761855878,\n",
      "          7161485785557625351,  -791603217686735930, -8073234054828320379,\n",
      "          6697335183227958692,  8272510222204194962,  3503147914264919405,\n",
      "         -4220482774061341626,  7992191607717270491,  4787867841899530171,\n",
      "         -1739394975695356845,  3858274714842055058, -1724804971567171253,\n",
      "          -934450845901486529,  8771164754136390630, -3607815064849577600,\n",
      "          4153255508344391051, -5489170022495304984],\n",
      "        [-5059799626625154252,  4018419957463656874, -8290649129793936806,\n",
      "          -897005669337016915,  1384288097808092837, -6116499113396019870,\n",
      "          4418922413453839706, -1271393438394528941,  3104621471055302115,\n",
      "          2993428741403194526, -6392592840450172685,  7316842984762436044,\n",
      "         -8353768518424366968,     8755026304194279, -7958222844869247582,\n",
      "         -5324032371224155731,  6165900992577393193,  3156228179727061554,\n",
      "         -1298596614228353220, -5061331658918791757],\n",
      "        [ 1802020044079025803,  -343778698498642214, -3159395575798114359,\n",
      "          3727370772984614605, -3807879696976380725,  6514189372512181316,\n",
      "          5439540574163055647,   861678929843743773,  1433643434180192914,\n",
      "          5094117382685914267, -4206753408962237896, -1698752178373592549,\n",
      "         -3776169503017186831,  5178958621628105462,  4084075470127052687,\n",
      "         -8298115243334168633,  5761137055731676542,  6756610556186669352,\n",
      "          2094848076619342703, -2457378252774136496],\n",
      "        [-3151060364810106052, -3707075866442278809,  -135433349445019395,\n",
      "         -7978604797186953406, -8788857442094380092,  5622861341412576354,\n",
      "          8280126003609821833,  2507978914183190421,  7028845855940299017,\n",
      "           446686375874428188,  1519619800423075082, -6055073243793591744,\n",
      "          6553497567996537645,  5662955957137939991,  4040731517525598866,\n",
      "          2832509464494416999, -6726715932622198490,  6241803335533754902,\n",
      "          4379048376978358304, -3406433108184111907],\n",
      "        [-5574887206633252383, -4668297088407170518,  6755796501449808638,\n",
      "         -5638319751820310240,   272347581222114273,  8402483745834794593,\n",
      "          6400192840025391830,  7029539428486515722, -8499147541546931782,\n",
      "          -256138704924594211, -1400978258840103728,  1345904730757762307,\n",
      "         -4053061447368843991,  4849585514068870641, -3658408054337311419,\n",
      "         -9162373730170692800, -1003409750783988259, -5573549515181001924,\n",
      "         -2774138968533881449,  6410766007994429635],\n",
      "        [-2285966041694886924, -6088865580633785160,  3100169037229030559,\n",
      "          4360825891147571734,  1201025728934033515,  3323844826170039493,\n",
      "         -3860953968784151937,  1934925740318307366,  2687760934242677884,\n",
      "          6799755389201172328,  6225058113978786186, -1125886707012987948,\n",
      "          2285404089305675195,  1212964470582649802,  5101376127383663607,\n",
      "          8816428446054666632,  6926685119686780564, -5911518042757606688,\n",
      "          9106946512584488430, -1454185375550044316],\n",
      "        [ -871830024799023016,  6927808415567779992,  2217834489795441362,\n",
      "         -3686627023652735423,  8641881540012636572, -5664993079619614271,\n",
      "            11321250521679443,  6584240857069233090,   123912050477602787,\n",
      "         -2446581728484375259, -7740249672561283393, -6131197306864045303,\n",
      "         -2003532343597972655, -8529858119616359432,  8821982808672517770,\n",
      "          6780668128973607128,  6962527185627876508,  2259904921608871337,\n",
      "          3267319720141630367,   483883619327158423],\n",
      "        [-1664067698734997594,  5438413113388565566,  -114263778615788316,\n",
      "          8468130232588451929,  9161102024062425633,  1037764378603539266,\n",
      "         -3201610995076286597, -2878843965929110468,  1918224261832450449,\n",
      "          5087662097033794277, -7998337521722065359,  4172561959441096761,\n",
      "         -7679048459908125152, -7185457518424449968, -8799764001898662743,\n",
      "          -806244725613366538, -2512046993578620025, -6888980170464134061,\n",
      "          3004995939317426160,  8040720496021103776],\n",
      "        [-7640561066326162362,  6710259425573366320, -1533416234573665174,\n",
      "          8842837292693760541,  9174212240539959379, -3232487333999585290,\n",
      "         -6333918664946563902,  2407368606877910135,  8504542366401619125,\n",
      "         -7097417211861264229, -3203708813332584173,    -3602260818240867,\n",
      "         -9198463643203183751,  -123438718394222774, -6875557647816688292,\n",
      "         -5554860000849611808,   360823675506039688,  5729239555515228842,\n",
      "          7570363495982222026,  1730868145333858167],\n",
      "        [ 1198267094046460473, -9211871037380297117, -7630297264267766485,\n",
      "         -8257884132102756891, -7502575841555270694,  3322178998259753134,\n",
      "          -303032168910410731, -7509818460691434637, -2203042558990589632,\n",
      "         -2738838113191390634,  -348047864767228305,  7263622927150704948,\n",
      "         -2099001691395382479,  3514732589224983508, -1059424150889734089,\n",
      "           823387445298606856,  7722430976087602677,  2877241036036369590,\n",
      "         -6734028628711860371,  6137062647064629400],\n",
      "        [-7980763840906122645,  5158010137481478829,  8880521668644864401,\n",
      "         -3471730662018818810, -6169847710731795053,  -175016032724578434,\n",
      "          5789409139377459633, -6330279644048819532, -4601567086388899802,\n",
      "           285909758107887425,  6311902017661258849,  -171752419167671446,\n",
      "          8007372946672702138, -5824059635372195636,  1646620772917520971,\n",
      "           870231174129749484,  5981125346727407589,  5991093816489803329,\n",
      "         -2919044177896102328,   125588372118165471],\n",
      "        [-3246534542844417032, -7987757889375080317,  -670895465703272190,\n",
      "            14004587257569646, -3512874416880070864, -7554676233475072570,\n",
      "          6312461216244287414, -4871488515387026548, -3397193830236604139,\n",
      "         -7431453889075627066, -6049284479493042274, -7969084920679936737,\n",
      "          1724555980706657390,  2747311981295341794,  -978758427590208119,\n",
      "          2502900030036063984, -4416439053442284005,  5639626587153770479,\n",
      "          5841826524270177655, -1644535514114658673],\n",
      "        [-8901665816634943520, -3390180275555494420,  7119399993751181245,\n",
      "          6500848905753482620, -9017641129816703782,   160597446155230267,\n",
      "          -828711576616706650,  6353038651946280090,  4251958405138404158,\n",
      "         -8002145631572543848, -2829084447389239784,  4590224135039250713,\n",
      "         -6141404809444654186,  7363505812932708706, -4057527531173767767,\n",
      "          -564765246271505756,  -735354108299915607, -4492946596460954517,\n",
      "         -3833288915019880674, -1633093870469364439],\n",
      "        [-3096321228258163482, -1171078095124647143,  1182833337450903896,\n",
      "         -8092057382312275677, -1986545372989683901, -3146191694487916511,\n",
      "          5609170999645340017,  2838589757622389881,  6930844655112814657,\n",
      "          4904157101124934276,  -413195842054429343,  7411999533332400993,\n",
      "           -91421627942534553, -6788268450090393010,  5750196517001958443,\n",
      "          3028487316553096347,  4614517169066619970,  3589421808265192173,\n",
      "          5205054376733757588, -5939436839656527390],\n",
      "        [ -955498825716513447, -8742431965319015909, -8435303285417479765,\n",
      "         -5607554543070043481,  -121411563924667333, -8530766972646229285,\n",
      "          8210119587282012347, -2528074068106649096,  4725248064326563238,\n",
      "          4063542483808374694, -1196904440037792867,   257731180553924052,\n",
      "          9003482059487282337, -5147443852922964954, -5585361001912861292,\n",
      "          4929359099781062062,  6895265642449802464,  1318506772258339815,\n",
      "          9158933136781523539, -5005154320728705969],\n",
      "        [-7921138440328675287, -5725677604287494399, -8631257697586942805,\n",
      "         -3710481243734080799,  2698126590502537872,  4750502255774544601,\n",
      "         -8760655019022521220, -5552522152491076019, -5222084412696661422,\n",
      "         -8927964718644100753, -6937682844795518963,   350384347315771187,\n",
      "          -465428159829327459,  8893772469101892355, -8224758675935131001,\n",
      "           903887265390764899,  7847180187450436540, -7524172328008938295,\n",
      "          6749118976185481850,  8660112862282139300],\n",
      "        [ -190658950294762058,  1707338501291959539, -1589612732858248763,\n",
      "          1905067327945285573,  3590105940216094546,  3069019493573296543,\n",
      "          1220668712536467895, -6002399923623364605, -1388861086361819007,\n",
      "          4014149806120105299,  4204920735773264399, -5132121800879221921,\n",
      "           134903385172610935,   308577127372839195, -1137181811110458863,\n",
      "          4480203466490329638,  3929597149448592185,  5620070400002448022,\n",
      "          7925899347186642726,   380797062681674626],\n",
      "        [  384230305013045399, -3707108391822377277,  -136238268131550793,\n",
      "          6611363138838096975, -3175533455578891019, -5303047717553610712,\n",
      "          5100912301398715039,  4594732522675589459, -3561972018393002124,\n",
      "          6914692015148754964,  8123254150916408122, -5828615005731911834,\n",
      "          2870138684126558997, -3332921374338507491, -8622176090539357947,\n",
      "          2269590695593339760,  3059530066723722656, -3200068751426495976,\n",
      "         -6242880926497271859,  1206013960657432713],\n",
      "        [  897753534172897473,  6026186658460857349, -6275391647377735221,\n",
      "          2028175511107756333,  -861017909823099661, -3062166583414886292,\n",
      "          -784172808121337049, -5145444230771508360, -3265482981092354851,\n",
      "           457436711997985623,  7059285552158905925,  6792363364974745778,\n",
      "          6723877520452834698,   -49513597429025525,  5164037053659995538,\n",
      "          7827477076500437424, -6152883832987031878, -7655163966954912261,\n",
      "            10152092230992215, -2400403273402878771],\n",
      "        [ 4522644822782935947, -7497241971278821985,   -46247083060319002,\n",
      "         -6424810050278544873, -1838710781581967638,  3271120454908141497,\n",
      "         -3598971713657907218,  2011534924104096851,  7278112731386451446,\n",
      "         -9070337044889237677, -1522140835537868807,  8168876062219842943,\n",
      "         -9121050801154444300,  1869010834478710857,  1874456830531236046,\n",
      "         -4544207262490144383,  5087761088833115595, -6328626340226842816,\n",
      "          7769973328954171407,   354739936415478663],\n",
      "        [-5023077148257095325,  9142045540918421212,  8124368404573109025,\n",
      "          1309367557477852167, -5397493417492380903, -2571186754771956092,\n",
      "          7155467189904480889,  1725094144550760857, -3953636715082696584,\n",
      "         -9081768812789276508, -1202924933255719222,  5980149064305636559,\n",
      "         -5347393046887221929,  9165815997248621253,   989472094204871706,\n",
      "         -5920606552462009715,  2573604071135100204, -4332599775569067303,\n",
      "          7027753541655180022,  5887346597856052540],\n",
      "        [-3072232718195427530,  7979626898752076125,   465534359703407707,\n",
      "          9006481542481397445,  6256578801946523496,  5873268712602423127,\n",
      "         -9084495113688473654, -8004868074680626643, -8773065499861172614,\n",
      "         -9021091821932514471,  2671625638389275715,  2216868032394922827,\n",
      "         -2740154731740386822, -3360717705325826642, -7923929540841714802,\n",
      "          8116318424363041067, -1153586551129992947,  2523308750451650605,\n",
      "          4844920406879834997,  6443921710529411918],\n",
      "        [-8252620037809566598, -1257836974547595051,  7396681426507076778,\n",
      "          1187581913760564906,  3439779390112724963,  2428106878027669509,\n",
      "         -3301087097051495428, -8321462126514004758, -9039035549847761437,\n",
      "         -6617485706818131397, -8508299050937766979,  8232794090757424904,\n",
      "          -330014019587443715,  2459813878351698625,  5708577894980274228,\n",
      "         -5151203305215889029, -2697151772340385148, -8317500622030088534,\n",
      "         -7890693063361928167, -7458533667935493328],\n",
      "        [  425106961942586030,   649213913224451968,  -150395228327422978,\n",
      "         -7357543830375380687,  1500616659331392133, -4838302666920245146,\n",
      "          1918038733103847445,  8485224577146588711, -8917356440794260182,\n",
      "         -1305576943086255589,  5528890363833625870, -6762141482675940252,\n",
      "         -9026868476831390032,  5840279297063629073, -9066739242496069952,\n",
      "          7104092284985778134,  2318934226290803780, -6556348858495999607,\n",
      "         -1079320520328865498,  4222262690078240708],\n",
      "        [ 6413338262059921606,  6432336869115763827, -9029255160147199873,\n",
      "          6712518494034821496,  7309553270851233673,  -719765795907518595,\n",
      "         -7513754457853413621,  -958897967925027712, -5215650165703987683,\n",
      "         -1477871788379290677, -4731825597781176767,  6164780856012740926,\n",
      "          4324779761825542041,  3948076389252557686,  1457075968923831235,\n",
      "          9183283457641629937,  7035755262283333722, -1864552537477772927,\n",
      "           208626188904568829,   648392306111757857],\n",
      "        [ 1742314276632276441,  6262511400905166345, -6957657787725902319,\n",
      "           555206913439463197, -4919176874386829706,  2706136903913761484,\n",
      "          7579289863236282736,  6689264427383962388, -7109639171331767854,\n",
      "          4238377419266770113,  6640390665044877704, -3501092941290047167,\n",
      "         -5303523680958196787, -5030131646692021252,  7867899537168775998,\n",
      "          3504634287924968852, -1427989359261211989,  8639584594163757742,\n",
      "         -2655989754083352196, -1763664808274889365],\n",
      "        [ 4625090628410462371, -1551823184564310234,  -272548831345272295,\n",
      "          8058035107573601109, -4109222861171459018,  2183495808364487321,\n",
      "          1025091435718018907,  3571317447199167510, -4294585937179259754,\n",
      "           652264404836795437, -9134054107274585842,   164050966537416929,\n",
      "          8133881697850073251,   410014187061669350,  7206669137554204863,\n",
      "         -9170160694968455089,  2351668681202797849, -6674785925692986287,\n",
      "         -2288537026666882555,  8361608753750547282],\n",
      "        [-2970927040035243595,  -102064214380552336,  2550065647906678510,\n",
      "          3945587656168862725,  1433118762913725812,     9394575094227023,\n",
      "          4697850800321759784,  9190572223261554106, -3163158741763062177,\n",
      "         -3586191571034591271,  2641169863125602701,  7094595763228795269,\n",
      "          2001605455582826988,  2587819944803238174,  6598117717172274056,\n",
      "          1501581216732051011,  2470554850243269564, -4382224691017284646,\n",
      "          -265338176479222993, -7707947569525077519],\n",
      "        [ -448973440237508283, -5668481434067461169,  6556370846405459412,\n",
      "         -4359991501281897848, -7723860711682150139,  1999393600559406393,\n",
      "          8065339678443370421, -6253047182964470548,  1608393183550405748,\n",
      "          -894163073599670340, -7398081314073574728,  1294175717407581890,\n",
      "          5327663804187096550, -5057762781288212539,  5531645269736853322,\n",
      "         -9164808187256042947, -5367342647165579197, -8211292552347364320,\n",
      "          7800300345597254731,  8775582227666459158],\n",
      "        [-7087538744488898402,   -71324593493398433,  5079035098068280821,\n",
      "          2897371957165489088, -8169243396085381339,  5066416249737573006,\n",
      "           878153728565771274, -1460199757601898298, -6175523913284634329,\n",
      "         -7977550345405961218, -1072203597033764488,  3795166315629905727,\n",
      "         -1325825798055638275,  5316356433302416892,  -640010069583345944,\n",
      "         -5960210806562953330,  -192080889111072460, -4178734398310434929,\n",
      "         -9145595423490095918,  3852102367022186087],\n",
      "        [ 1450498848613440506,  4476351462871293206, -2983227622992330186,\n",
      "          7019738032153372904,  1660084250843424693, -1663747035042896396,\n",
      "           846300777164266256,  -111862877772816897,  6791724864670604770,\n",
      "          9216666196725853187, -8238764167305235423,  -317458994675102525,\n",
      "         -3926722041467190989,  7084335493649737438,  3696111319332937650,\n",
      "         -8797237186685758732,  2489950163600941174,  6857294917005513518,\n",
      "         -3828181020203219696,  3139583186473422697],\n",
      "        [ 6054926890003484738,  8926380962176732695,  5149284032031012200,\n",
      "          2026905383668573225,  9114954337744282252, -3872589104977056217,\n",
      "         -5936069805140840409,  8274430209563280780,  1599837026427929158,\n",
      "          6384397941621638319, -4728888217283316063, -8241274468487179232,\n",
      "         -8474314079711861821,  8819892876572371554,  7381508832730403253,\n",
      "         -4381344798507207039,  6204271748461702877,  7400427312031038036,\n",
      "         -2554173454353633752, -5277018027173003844],\n",
      "        [ 7944376256664640032,  5455844580794092771,  2718917618784366528,\n",
      "          1446918641108174210, -5095919579428263182, -8610162122745190651,\n",
      "         -6653767103405782287, -6964666186680975438,  7678252218668021955,\n",
      "          6613127722186617176,  5920307568731057676,  2403342501430433831,\n",
      "         -6095159482042614836,    68305334366469333,  -358284954415116835,\n",
      "           816441605961530838,  1596691498230473751, -3098117025366557695,\n",
      "         -8584684413267518585,    70151954822086805],\n",
      "        [-1331421873457505954,  8564211584904470106,  7966470543710227163,\n",
      "           936748101064604414, -1689405075828262290,  7684199016821219637,\n",
      "          3804620734898518314, -1139271244650977863, -2130747957689427914,\n",
      "         -3015961184383120271, -1182468933528048343,  8685520121451985513,\n",
      "          7556840511666856594, -1111827956081712206,  5488079210731629785,\n",
      "           891170382838384221, -7331539855517524307, -5029142643046454378,\n",
      "         -4190357847667284986, -1069495238903814292],\n",
      "        [ 4046781561590935028, -9180094415871003122,  4707597590243518474,\n",
      "           781749822535115623,  8035914767086126100,  3794914767809020767,\n",
      "          1586702556949964448,  -768281437453286035,  6577733879547131696,\n",
      "         -1567847805180514245,  8013888204860988175,   554351596679833808,\n",
      "         -4043810229850630860,  5373802535051551150, -6026288967323391994,\n",
      "          6753465998843325707,  6725861495115809338, -4963730242009084937,\n",
      "         -5304438087961237905,  8698357261078065614],\n",
      "        [-5662398479999544450, -7024714475705626910,   208176593926122389,\n",
      "          -364728868877065745, -3272551269761042701,    -9251802087605829,\n",
      "          1326093198802942798, -2051584500527563722, -5896483512933842814,\n",
      "         -1868086579098558155,  -567794979396210951, -7797629229272622976,\n",
      "          1142901938209886686, -6406929267942775287,  6458255166316723418,\n",
      "         -7466280600161735190,  1984856538309075760, -7003857852013280557,\n",
      "          1038508468976390446,  6458171055046879296],\n",
      "        [-5930971291518056143, -2898398495430275416,  1530849834354829579,\n",
      "         -1196160232662674700,   648054690039574868, -8368100994950470215,\n",
      "         -8371960632236356144,  6984205168240189969,  4394913523439753171,\n",
      "         -3765643703687786419,   735910817256530783, -3121095699697357807,\n",
      "          2456660949664267547, -7987315288959800429,  6252191078072717266,\n",
      "         -2828775317575744008, -8446056724744797961, -2074045907389687365,\n",
      "           764251726910536265, -8005219691960670217],\n",
      "        [-7495120479645877020, -7287911309769420603,  5810469970878376748,\n",
      "          8019463442066728517,  3250838741525588731,  5492449808811358555,\n",
      "          3000949898338945021,  3990665404925616279, -8647370644068087714,\n",
      "          2833064331704945666,  5357222202002864842,  6928157816118361554,\n",
      "          4634200095361923452, -5045996685355558877,  5594476441419316486,\n",
      "          8552334997175928581,   891044740467143465,  1526307275757315714,\n",
      "         -1892135258001366988, -8913580045854206880],\n",
      "        [-2523958018626435353, -6037449390396437340,   569987554383744588,\n",
      "          4232426311378294773, -8449994104415828772, -7961869621551932177,\n",
      "         -3960351184223348022, -7916221863774567226, -7467363222375276622,\n",
      "          3181876863646823294,  1760113463615058179,  6353882072896997195,\n",
      "          8524838574106264384,  8816905745546578885, -4238663309990613976,\n",
      "          1210616418622435547, -8209156194855646821, -3700351072225703376,\n",
      "          3675195929713850645, -7225378140593571817],\n",
      "        [-4872837479633665772,  7756622149778894056,  1734599136278503438,\n",
      "         -7425684759967869870, -1099696189986581548,   137453477889253947,\n",
      "          7417840268268154059,  1042124434166750703,  -995232035450191259,\n",
      "         -1062303894859909265,  1656027546650659123, -1475805116144206650,\n",
      "           642087968171677715, -9041710781098432389,  5613261361835378308,\n",
      "         -5149159337529693179,  8430780005438128591,  3119460160067543604,\n",
      "         -4947905885479963934, -1402462229867834941],\n",
      "        [ 8651255687754064785, -1580277772518511781,  8142792169031679245,\n",
      "          6468063964214798094,   907424654041835770, -4600619370995047913,\n",
      "          1366986037093685110, -3469195805208583173,  8518981736172291438,\n",
      "           -56443503207459465,  6628302999580749294,  4586783482849682514,\n",
      "          2974304215068827644, -8059620548220149658,   747352923644231982,\n",
      "         -1768558814936954192,  1818465202411967522,  4573476623192343324,\n",
      "          6979576908458759431, -6406648639289226656]])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/george/miniconda3/envs/crypten/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"<ipython-input-12-b83eec178921>\", line 16, in step_through_two_layers\n",
      "    out_enc = private_model._modules['5'].forward(data_enc)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 538, in forward_function\n",
      "    res = object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/home/george/contrib/CrypTen/crypten/nn/module.py\", line 1465, in forward\n",
      "    output = x.matmul(self.weight.t())\n",
      "  File \"/home/george/contrib/CrypTen/crypten/cryptensor.py\", line 250, in __torch_function__\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: CrypTen does not support torch function <method 'matmul' of 'torch._C._TensorBase' objects>.\n",
      "ERROR:root:One of the parties failed. Check past logs\n"
     ]
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def step_through_two_layers():    \n",
    "    rank = comm.get().get_rank()\n",
    "\n",
    "    # Load and encrypt the network\n",
    "    model = crypten.load_from_party(sample_trained_model_file, model_class=AliceNet, src=ALICE)\n",
    "    private_model = crypten.nn.from_pytorch(model, dummy_input=torch.empty((1, 50)))\n",
    "    private_model.encrypt(src=ALICE)\n",
    "\n",
    "    # Load and encrypt the data\n",
    "    data_enc = crypten.load_from_party(sample_data_bob_file, src=BOB)\n",
    "\n",
    "    # Forward through the first layer\n",
    "    out_enc = private_model._modules['5'].forward(data_enc)\n",
    "    encrypted = crypten.is_encrypted_tensor(out_enc)\n",
    "    crypten.print(f\"Rank: {rank}\\n\\tFirst Linear Layer: Output Encrypted: {encrypted}\", in_order=True)\n",
    "    crypten.print(f\"Rank: {rank}\\n\\tShares after First Linear Layer:{out_enc.share}\", in_order=True)\n",
    "\n",
    "    # Apply ReLU activation\n",
    "    out_enc = private_model._modules['6'].forward(out_enc)\n",
    "    encrypted = crypten.is_encrypted_tensor(out_enc)\n",
    "    crypten.print(f\"Rank: {rank}\\n\\tReLU:\\n Output Encrypted: {encrypted}\", in_order=True)\n",
    "    crypten.print(f\"Rank: {rank}\\n\\tShares after ReLU: {out_enc.share}\\n\", in_order=True)\n",
    "\n",
    "    # Forward through the second Linear layer\n",
    "    out_enc = private_model._modules['output'].forward(out_enc)\n",
    "    encrypted = crypten.is_encrypted_tensor(out_enc)\n",
    "    crypten.print(f\"Rank: {rank} Second Linear layer:\\n Output Encrypted: {encrypted}\\n\", in_order=True) \n",
    "    crypten.print(f\"Rank: {rank} Shares after Second Linear layer:{out_enc.share}\\n\", in_order=True)\n",
    "\n",
    "    # Decrypt the output\n",
    "    out_dec = out_enc.get_plain_text()\n",
    "    \n",
    "    # Since both parties have same decrypted results, only print the rank 0 output\n",
    "    crypten.print(\"Decrypted output:\\n Output Encrypted:\", crypten.is_encrypted_tensor(out_dec))\n",
    "    crypten.print(\"Tensors:\\n\", out_dec)\n",
    "    \n",
    "z = step_through_two_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we emphasize that the output of each layer is an encrypted tensor. Only after the final call to `get_plain_text` do we get the plaintext tensor.\n",
    "\n",
    "### From PyTorch to CrypTen: Structural Changes in Network Architecture \n",
    "\n",
    "We have used a simple two-layer network in the above example, but the same ideas apply to more complex networks and operations. However, in more complex networks, there may not always be a one-to-one mapping between the PyTorch layers and the CrypTen layers. This is because we use PyTorch's onnx implementation to convert PyTorch models to CrypTen models. \n",
    "As an example, we'll take a typical network used to classify digits in MNIST data, and look at what happens to its structure we convert it to a CrypTen module. (As we only wish to illustrate the structural changes in layers, we will not train this network on data; we will just use it with its randomly initialized weights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 46 \tModule: Conv2d encrypted module\n",
      "Name: 26 \tModule: ReLU encrypted module\n",
      "Name: 27 \tModule: _ConstantPad encrypted module\n",
      "Name: 28 \tModule: AvgPool2d encrypted module\n",
      "Name: 49 \tModule: Conv2d encrypted module\n",
      "Name: 31 \tModule: ReLU encrypted module\n",
      "Name: 32 \tModule: _ConstantPad encrypted module\n",
      "Name: 33 \tModule: AvgPool2d encrypted module\n",
      "Name: 34 \tModule: Shape encrypted module\n",
      "Name: 36 \tModule: Gather encrypted module\n",
      "Name: 37 \tModule: Constant encrypted module\n",
      "Name: 38 \tModule: Unsqueeze encrypted module\n",
      "Name: 39 \tModule: Unsqueeze encrypted module\n",
      "Name: 40 \tModule: Concat encrypted module\n",
      "Name: 41 \tModule: Reshape encrypted module\n",
      "Name: 42 \tModule: Linear encrypted module\n",
      "Name: 43 \tModule: _BatchNorm encrypted module\n",
      "Name: 44 \tModule: ReLU encrypted module\n",
      "Name: output \tModule: Linear encrypted module\n"
     ]
    }
   ],
   "source": [
    "# Define Alice's network\n",
    "class AliceNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AliceNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=5, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(100)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = AliceNet2()\n",
    "\n",
    "# Let's encrypt the complex network. \n",
    "# Create dummy input of the correct input shape for the model\n",
    "dummy_input = torch.empty((1, 1, 28, 28))\n",
    "\n",
    "# Encrypt the network\n",
    "private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "private_model.encrypt(src=ALICE)\n",
    "\n",
    "# Examine the structure of the encrypted network\n",
    "for name, curr_module in private_model._modules.items():\n",
    "    print(\"Name:\", name, \"\\tModule:\", curr_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the CrypTen network has split some the layers in the PyTorch module into several CrypTen modules. Each PyTorch operation may correspond to one or more operations in CrypTen. However, during the conversion, these are sometimes split due to limitations intorduced by onnx.\n",
    "\n",
    "Before exiting this tutorial, please clean up the files generated using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for fn in temp_files:\n",
    "    if os.path.exists(fn): os.remove(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
